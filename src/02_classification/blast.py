import argparse
import glob
import multiprocessing.dummy as mp
import os.path
import pandas as pd
from pathlib import Path
import subprocess
from tqdm import tqdm
from typing import Union


class Blast:
    def __init__(self, job_id: str, root_dir: Union[Path, str], marker: str,
                 records_f: str, num_workers: int):
        self.job_id = job_id
        self.root_dir = root_dir
        self.num_workers = num_workers
        self.marker = marker

        # set up data and directories
        self.records = pd.read_csv(records_f, header=0, sep='\t')
        self.subset = self.records.loc[self.records['fold'] == 0, :]
        self.blast_results_dir = f'{root_dir}/results/blast/{job_id}'
        self.results_dir = f'{root_dir}/results/{job_id}'

    # create fasta for training/validation subset
    def write_to_fasta(self, record, loo_idx: int = None):
        seq = record['unaligned_barcode']
        # _near_but_not_hesperitis can be found in Lycaenidae dataset; name was too long for makeblastdb
        # no duplicates are generated by this replacement
        rec_id = f'{record["species_name"].replace(" ", "_").replace("_near_but_not_hesperitis", "")}|{record["record_id"]}'
        if loo_idx is not None:
            f = f'{self.blast_results_dir}/{loo_idx}/query.fasta' if record.name == loo_idx else f'{self.blast_results_dir}/{loo_idx}/database.fasta'
        else:
            f = f'{self.blast_results_dir}/non_loo/{record["dataset"]}.fasta'

        with open(f, 'a+') as f:
            f.write(f'>{rec_id}\n')
            f.write(f'{seq}\n')

    # run makeblastdb command using created
    def create_blast_db(self, loo_idx: int = None):
        if loo_idx is not None:
            db_fasta = f'{self.blast_results_dir}/{loo_idx}/database.fasta'
            title = f"{self.job_id}_LOO{loo_idx}"
        else:
            db_fasta = f'{self.blast_results_dir}/non_loo/train.fasta'
            title = f"{self.job_id}_train"

        if os.path.isfile(f'{db_fasta}.ndb'):
            return

        subprocess.run(['makeblastdb',
                        '-in', db_fasta,
                        '-blastdb_version', '5',
                        '-parse_seqids',
                        '-title', title,
                        '-dbtype', 'nucl'],
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE
                       )

    # run blastn command against custom database; always select first match
    def blast_against_db(self, loo_idx: int = None):
        if loo_idx is not None:
            db_fasta = os.path.abspath(f'{self.blast_results_dir}/{loo_idx}/database.fasta')
            query_fasta = os.path.abspath(f'{self.blast_results_dir}/{loo_idx}/query.fasta')
            result = os.path.abspath(f'{self.blast_results_dir}/{loo_idx}/{loo_idx}.txt')
        else:
            db_fasta = os.path.abspath(f'{self.blast_results_dir}/non_loo/train.fasta')
            query_fasta = os.path.abspath(f'{self.blast_results_dir}/non_loo/val.fasta')
            result = os.path.abspath(f'{self.blast_results_dir}/non_loo/{self.job_id}.txt')

        if os.path.isfile(result):
            return

        subprocess.run(['blastn',
                        '-db', db_fasta,
                        '-query', query_fasta,
                        '-out', result,
                        "-outfmt", '6 delim=\t qseqid qlen sseqid slen evalue score pident nident mismatch gaps'],
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE
                       )

        df = pd.read_csv(result, header=None, sep='\t',
                         names=['qseqid', 'qlen', 'sseqid',
                                'slen', 'evalue', 'score', 'pident',
                                'nident', 'mismatch', 'gaps'])
        # split seqid columns into species name and record ID
        df[['query_species', 'qseqid']] = df['qseqid'].str.split('|', expand=True)
        df[['subject_species', 'sseqid']] = df['sseqid'].str.split('|', expand=True)
        df['match'] = df['query_species'] == df['subject_species']

        df = df.groupby('qseqid').head(1)
        df['val_idx'] = loo_idx
        df.to_csv(result, header=True, index=False, sep='\t')

    # run leave-one-out with BLAST
    def run_loo(self, idx: int):
        Path(f'{self.blast_results_dir}/{idx}').mkdir(parents=True, exist_ok=True)
        if not os.path.isfile(f'{self.blast_results_dir}/{idx}/database.fasta'):
            self.records.apply(lambda x: self.write_to_fasta(x, loo_idx=idx), axis=1)
        self.create_blast_db(idx)
        self.blast_against_db(idx)

    def run_traditional(self):
        Path(f'{self.blast_results_dir}/non_loo').mkdir(parents=True, exist_ok=True)
        # create fastas BLAST databases will be based on
        if not os.path.isfile(f'{self.blast_results_dir}/non_loo/train.fasta'):
            self.records.apply(lambda x: self.write_to_fasta(x), axis=1)
        self.create_blast_db()
        self.blast_against_db()

        # add BLAST results to overall results file
        overall_result_df = pd.read_csv(f'{self.blast_results_dir}/results.tsv', header=0, sep='\t')
        df = pd.read_csv(os.path.abspath(f'{self.blast_results_dir}/non_loo/{self.job_id}.txt'), header=0, sep='\t')
        overall_result_df.loc[len(overall_result_df)] = ['unaligned_barcode', None, 'sep', 'BLAST', df['match'].mean(),
                                                         None]
        overall_result_df.to_csv(f'{self.blast_results_dir}/results.tsv', header=True, index=False, sep='\t')

    # TODO: update so not only loo is possible but also k-fold
    def run_cv(self):
        with mp.Pool(self.num_workers) as pool:
            list(tqdm(pool.imap(self.run_loo,
                                self.subset['val_idx']),
                      total=len(self.subset['val_idx'])))

        # concatenate results and print out LOO accuracy
        res = pd.concat([pd.read_csv(f, header=0, sep='\t') for f in glob.glob(f'{self.blast_results_dir}/*/*.txt')])
        res.to_csv(f'{self.blast_results_dir}/results.txt', header=True, index=False, sep='\t')

        print(f"LOO accuracy: {res['match'].mean()}")

        # save as column subset for plots + statistics
        res['val_acc'] = res.match.replace({True: 1.0, False: 0.0})
        res = res[['val_acc', 'val_idx']].copy()
        res[['barcode_processing', 'barcode_encoding',
             'round_1', 'round_2', 'val_loss', 'best_epoch']] = ['unaligned_barcode', None, 'sep', 'BLAST', None, None]
        res.to_csv(f'{self.blast_results_dir}/results_blast.tsv', header=True, index=False, sep='\t')
